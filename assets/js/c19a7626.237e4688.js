"use strict";(globalThis.webpackChunktmp_docusaurus_project=globalThis.webpackChunktmp_docusaurus_project||[]).push([[338],{8189:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});const o=JSON.parse('{"id":"course-outline","title":"Physical AI & Humanoid Robotics: Course Outline","description":"This outline provides a structured overview of the \\"Physical AI & Humanoid Robotics: From Simulation to Reality\\" textbook, compatible with Docusaurus for easy navigation.","source":"@site/docs/course-outline.md","sourceDirName":".","slug":"/course-outline","permalink":"/roboailearner/docs/course-outline","draft":false,"unlisted":false,"editUrl":"https://github.com/EngineerAbdullahIqbal/roboailearner/tree/main/robotics_book_content/docs/course-outline.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","next":{"title":"Chapter 1: Introduction to Physical AI and Embodied Intelligence","permalink":"/roboailearner/docs/module-1/chapter-1"}}');var t=i(4848),r=i(8453);const s={},a="Physical AI & Humanoid Robotics: Course Outline",d={},l=[{value:"Module 1: Foundations of Physical AI &amp; ROS 2",id:"module-1-foundations-of-physical-ai--ros-2",level:2},{value:"Chapter 1: Introduction to Embodied AI and Robotics",id:"chapter-1-introduction-to-embodied-ai-and-robotics",level:3},{value:"Chapter 2: ROS 2 Fundamentals: Nodes, Topics, and Services",id:"chapter-2-ros-2-fundamentals-nodes-topics-and-services",level:3},{value:"Chapter 3: ROS 2 Tools: Rviz, Gazebo, and the CLI",id:"chapter-3-ros-2-tools-rviz-gazebo-and-the-cli",level:3},{value:"Module 2: Sensing and Perception for Humanoids",id:"module-2-sensing-and-perception-for-humanoids",level:2},{value:"Chapter 4: Camera Systems and Image Processing in ROS 2",id:"chapter-4-camera-systems-and-image-processing-in-ros-2",level:3},{value:"Chapter 5: Lidar and Depth Sensing: Building Point Clouds",id:"chapter-5-lidar-and-depth-sensing-building-point-clouds",level:3},{value:"Chapter 6: Sensor Fusion: Combining Data for Robust Perception",id:"chapter-6-sensor-fusion-combining-data-for-robust-perception",level:3},{value:"Module 3: Motion, Control, and Navigation",id:"module-3-motion-control-and-navigation",level:2},{value:"Chapter 7: Inverse Kinematics and Humanoid Motion Planning",id:"chapter-7-inverse-kinematics-and-humanoid-motion-planning",level:3},{value:"Chapter 8: Robot Control: Actuators, Joints, and PID",id:"chapter-8-robot-control-actuators-joints-and-pid",level:3},{value:"Chapter 9: Navigation with ROS 2 Nav2: Mapping and Path Planning",id:"chapter-9-navigation-with-ros-2-nav2-mapping-and-path-planning",level:3},{value:"Module 4: Advanced Topics and Real-World Deployment",id:"module-4-advanced-topics-and-real-world-deployment",level:2},{value:"Chapter 10: Vision-Language-Action (VLA) Models for Humanoids",id:"chapter-10-vision-language-action-vla-models-for-humanoids",level:3},{value:"Chapter 11: Real-World Deployment: Bridging the Sim-to-Real Gap",id:"chapter-11-real-world-deployment-bridging-the-sim-to-real-gap",level:3},{value:"Chapter 12: Safety, Ethics, and Future of Humanoid Robotics",id:"chapter-12-safety-ethics-and-future-of-humanoid-robotics",level:3},{value:"Chapter 13: Project: Building an Autonomous Humanoid Application",id:"chapter-13-project-building-an-autonomous-humanoid-application",level:3},{value:"Module 5: Capstone Projects (Beginner to Advanced)",id:"module-5-capstone-projects-beginner-to-advanced",level:2},{value:"Chapter 14: Student Projects Overview",id:"chapter-14-student-projects-overview",level:3},{value:"Project 1: Sentient Sentry \u2013 Camera-Based Face Tracking",id:"project-1-sentient-sentry--camera-based-face-tracking",level:3},{value:"Project 2: Visual Sorter Arm \u2013 Object Identification and Sorting",id:"project-2-visual-sorter-arm--object-identification-and-sorting",level:3},{value:"Project 3: Office Runner \u2013 Autonomous Item Delivery",id:"project-3-office-runner--autonomous-item-delivery",level:3}];function c(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"physical-ai--humanoid-robotics-course-outline",children:"Physical AI & Humanoid Robotics: Course Outline"})}),"\n",(0,t.jsx)(n.p,{children:'This outline provides a structured overview of the "Physical AI & Humanoid Robotics: From Simulation to Reality" textbook, compatible with Docusaurus for easy navigation.'}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-1-foundations-of-physical-ai--ros-2",children:"Module 1: Foundations of Physical AI & ROS 2"}),"\n",(0,t.jsx)(n.h3,{id:"chapter-1-introduction-to-embodied-ai-and-robotics",children:"Chapter 1: Introduction to Embodied AI and Robotics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Explore the fundamental concepts of embodied intelligence and the role of robotics in the physical world."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-1/chapter-1.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-2-ros-2-fundamentals-nodes-topics-and-services",children:"Chapter 2: ROS 2 Fundamentals: Nodes, Topics, and Services"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Learn the core components of ROS 2, understanding how nodes communicate through topics and services."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-1/chapter-2.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-3-ros-2-tools-rviz-gazebo-and-the-cli",children:"Chapter 3: ROS 2 Tools: Rviz, Gazebo, and the CLI"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Master essential ROS 2 tools for visualization (Rviz), simulation (Gazebo), and command-line interface operations."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-1/chapter-3.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-2-sensing-and-perception-for-humanoids",children:"Module 2: Sensing and Perception for Humanoids"}),"\n",(0,t.jsx)(n.h3,{id:"chapter-4-camera-systems-and-image-processing-in-ros-2",children:"Chapter 4: Camera Systems and Image Processing in ROS 2"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Dive into camera sensor integration and basic image processing techniques within the ROS 2 framework."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-2/chapter-4.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-5-lidar-and-depth-sensing-building-point-clouds",children:"Chapter 5: Lidar and Depth Sensing: Building Point Clouds"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Understand how LiDAR and depth cameras work and how to process their data to create 3D point clouds."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-2/chapter-5.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-6-sensor-fusion-combining-data-for-robust-perception",children:"Chapter 6: Sensor Fusion: Combining Data for Robust Perception"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Learn advanced techniques for combining data from multiple sensors to achieve a more robust understanding of the environment."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-2/chapter-6.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-3-motion-control-and-navigation",children:"Module 3: Motion, Control, and Navigation"}),"\n",(0,t.jsx)(n.h3,{id:"chapter-7-inverse-kinematics-and-humanoid-motion-planning",children:"Chapter 7: Inverse Kinematics and Humanoid Motion Planning"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Explore the principles of inverse kinematics and develop strategies for planning complex humanoid movements."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-3/chapter-7.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-8-robot-control-actuators-joints-and-pid",children:"Chapter 8: Robot Control: Actuators, Joints, and PID"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Implement control strategies using actuators, managing robot joints, and understanding PID controllers."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-3/chapter-8.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-9-navigation-with-ros-2-nav2-mapping-and-path-planning",children:"Chapter 9: Navigation with ROS 2 Nav2: Mapping and Path Planning"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Utilize the ROS 2 Nav2 stack for autonomous navigation, including mapping, localization, and path planning."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-3/chapter-9.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-4-advanced-topics-and-real-world-deployment",children:"Module 4: Advanced Topics and Real-World Deployment"}),"\n",(0,t.jsx)(n.h3,{id:"chapter-10-vision-language-action-vla-models-for-humanoids",children:"Chapter 10: Vision-Language-Action (VLA) Models for Humanoids"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Introduce cutting-edge Vision-Language-Action models and their application in intelligent humanoid behavior."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-4/chapter-10.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-11-real-world-deployment-bridging-the-sim-to-real-gap",children:"Chapter 11: Real-World Deployment: Bridging the Sim-to-Real Gap"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Address the challenges of deploying simulated robotics solutions to physical hardware and techniques to bridge the sim-to-real gap."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-4/chapter-11.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-12-safety-ethics-and-future-of-humanoid-robotics",children:"Chapter 12: Safety, Ethics, and Future of Humanoid Robotics"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Discuss critical considerations for safety, ethical implications, and the future trends in humanoid robotics."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-4/chapter-12.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"chapter-13-project-building-an-autonomous-humanoid-application",children:"Chapter 13: Project: Building an Autonomous Humanoid Application"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": A culminating project to integrate learned concepts into a complete, autonomous humanoid robotic application."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-4/chapter-13.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"module-5-capstone-projects-beginner-to-advanced",children:"Module 5: Capstone Projects (Beginner to Advanced)"}),"\n",(0,t.jsx)(n.h3,{id:"chapter-14-student-projects-overview",children:"Chapter 14: Student Projects Overview"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Introduction to the hands-on physical AI robotics projects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-5/chapter-14-student-projects.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"project-1-sentient-sentry--camera-based-face-tracking",children:"Project 1: Sentient Sentry \u2013 Camera-Based Face Tracking"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Implement a ROS 2-based system for face detection and camera tracking."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-5/project-1-sentient-sentry.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"project-2-visual-sorter-arm--object-identification-and-sorting",children:"Project 2: Visual Sorter Arm \u2013 Object Identification and Sorting"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Build a robotic arm system that identifies and sorts colored objects."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-5/project-2-visual-sorter.md"})]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"project-3-office-runner--autonomous-item-delivery",children:"Project 3: Office Runner \u2013 Autonomous Item Delivery"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Description"}),": Develop an autonomous mobile robot for item delivery using Nav2."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"File Path"}),": ",(0,t.jsx)(n.code,{children:"docs/module-5/project-3-office-runner.md"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>a});var o=i(6540);const t={},r=o.createContext(t);function s(e){const n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);